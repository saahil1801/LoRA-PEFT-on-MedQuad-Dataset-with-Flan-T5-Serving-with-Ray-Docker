{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments, EvalPrediction,AutoModelForSequenceClassification,AutoModelForCausalLM\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments,DataCollatorForSeq2Seq\n",
    "from peft import LoraConfig, get_peft_model,  TaskType\n",
    "from datasets import  load_dataset ,Dataset,DatasetDict,load_metric\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import sentencepiece\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaahilkatariads\u001b[0m (\u001b[33msaahilkatariads-MCKV Institute of Engineering\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/wandb/run-20240910_021335-mom4tms9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/saahilkatariads-MCKV%20Institute%20of%20Engineering/loramedical/runs/mom4tms9' target=\"_blank\">fresh-puddle-2</a></strong> to <a href='https://wandb.ai/saahilkatariads-MCKV%20Institute%20of%20Engineering/loramedical' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/saahilkatariads-MCKV%20Institute%20of%20Engineering/loramedical' target=\"_blank\">https://wandb.ai/saahilkatariads-MCKV%20Institute%20of%20Engineering/loramedical</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/saahilkatariads-MCKV%20Institute%20of%20Engineering/loramedical/runs/mom4tms9' target=\"_blank\">https://wandb.ai/saahilkatariads-MCKV%20Institute%20of%20Engineering/loramedical/runs/mom4tms9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/saahilkatariads-MCKV%20Institute%20of%20Engineering/loramedical/runs/mom4tms9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x3417d1ac0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "# Initialize a new run\n",
    "wandb.init(project='loramedical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "dataset = dataset.drop('qtype', axis=1)\n",
    "dataset = dataset.rename(columns={'Question': 'question', 'Answer': 'answer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(dataset, test_size=0.2, random_state=56)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_train.reset_index(drop=True)\n",
    "df_test = df_train.reset_index(drop=True)\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "val_dataset = Dataset.from_pandas(df_val)\n",
    "test_dataset = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"Assuming you are working as Doctor. Please answer this question: \"\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "   inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "   model_inputs = tokenizer(inputs, max_length=256, truncation=True)\n",
    "   labels = tokenizer(text_target=examples[\"answer\"], \n",
    "                      max_length=256,         \n",
    "                      truncation=True)\n",
    "\n",
    "   model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "   return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9843/9843 [00:05<00:00, 1835.76 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9843/9843 [00:05<00:00, 1850.64 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9843/9843 [00:05<00:00, 1870.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = health_dataset_dict.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=32,  # Rank\n",
    "    lora_alpha=16,  # Scaling\n",
    "    lora_dropout=0.01,  # Dropout probability\n",
    "    bias=\"none\",  # Bias term setting\n",
    "    target_modules=[\"q\",'v'],\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    "        # Apply LoRA to the query and value projection layers\n",
    "     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',           # output directory\n",
    "    evaluation_strategy='epoch',      # evaluation is done at the end of each epoch\n",
    "    learning_rate=1e-4,               # learning rate\n",
    "    per_device_train_batch_size=8,    # batch size for training\n",
    "    per_device_eval_batch_size=16,    # batch size for evaluation\n",
    "    weight_decay=0.01,                # strength of weight decay\n",
    "    save_total_limit=3,               # limits the total amount of checkpoints. Deletes older checkpoints.\n",
    "    num_train_epochs=15,               # number of training epochs\n",
    "    predict_with_generate=True,       # generate predictions for evaluation\n",
    "    report_to='wandb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "  3%|â–Ž         | 500/18465 [2:04:01<120:43:12, 24.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.273, 'grad_norm': 0.1970219910144806, 'learning_rate': 9.729217438396968e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/peft/utils/other.py:619: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: aefcc6c7-8877-4baa-be43-59d89a4fdb16)') - silently ignoring the lookup for the file config.json in google/flan-t5-large.\n",
      "  warnings.warn(\n",
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/peft/utils/save_and_load.py:218: UserWarning: Could not find a config file in google/flan-t5-large - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "  5%|â–Œ         | 1000/18465 [4:41:40<8:08:24,  1.68s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.024, 'grad_norm': 0.2271500676870346, 'learning_rate': 9.458434876793935e-05, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 1231/18465 [5:56:39<6:13:50,  1.30s/it]    \n",
      "  7%|â–‹         | 1231/18465 [8:10:47<6:13:50,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7467290163040161, 'eval_runtime': 8048.7748, 'eval_samples_per_second': 1.223, 'eval_steps_per_second': 0.077, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 1500/18465 [9:46:43<13:50:36,  2.94s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9672, 'grad_norm': 0.2017890363931656, 'learning_rate': 9.187652315190903e-05, 'epoch': 1.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/peft/utils/other.py:619: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: fedac79b-b6d5-43a1-85c7-6c8116ef46d8)') - silently ignoring the lookup for the file config.json in google/flan-t5-large.\n",
      "  warnings.warn(\n",
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/peft/utils/save_and_load.py:218: UserWarning: Could not find a config file in google/flan-t5-large - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      " 11%|â–ˆ         | 2000/18465 [10:02:28<8:14:45,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9213, 'grad_norm': 0.3887452781200409, 'learning_rate': 8.916869753587869e-05, 'epoch': 1.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 13%|â–ˆâ–Ž        | 2462/18465 [10:30:36<8:37:05,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.680251121520996, 'eval_runtime': 828.3144, 'eval_samples_per_second': 11.883, 'eval_steps_per_second': 0.744, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–Ž        | 2500/18465 [10:32:16<8:58:02,  2.02s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8741, 'grad_norm': 0.20996493101119995, 'learning_rate': 8.646087191984836e-05, 'epoch': 2.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 3000/18465 [10:50:28<10:17:06,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8742, 'grad_norm': 0.21190248429775238, 'learning_rate': 8.375304630381803e-05, 'epoch': 2.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/peft/utils/other.py:619: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: bf422762-354b-479a-a95a-99f72cd13440)') - silently ignoring the lookup for the file config.json in google/flan-t5-large.\n",
      "  warnings.warn(\n",
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/peft/utils/save_and_load.py:218: UserWarning: Could not find a config file in google/flan-t5-large - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      " 19%|â–ˆâ–‰        | 3500/18465 [11:11:50<8:08:44,  1.96s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.849, 'grad_norm': 0.2802028954029083, 'learning_rate': 8.104522068778771e-05, 'epoch': 2.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 20%|â–ˆâ–ˆ        | 3693/18465 [11:34:56<10:37:27,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6409293413162231, 'eval_runtime': 983.5409, 'eval_samples_per_second': 10.008, 'eval_steps_per_second': 0.626, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 4000/18465 [11:49:10<9:05:48,  2.26s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8315, 'grad_norm': 0.20034688711166382, 'learning_rate': 7.833739507175738e-05, 'epoch': 3.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/peft/utils/other.py:619: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: d2762281-7ee5-41a3-8798-98c94d863c16)') - silently ignoring the lookup for the file config.json in google/flan-t5-large.\n",
      "  warnings.warn(\n",
      "/Users/saahil/Desktop/Coding_Projects/LLMS/LoraPeft-BioMRc/env2/lib/python3.9/site-packages/peft/utils/save_and_load.py:218: UserWarning: Could not find a config file in google/flan-t5-large - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      " 24%|â–ˆâ–ˆâ–       | 4500/18465 [12:10:51<9:46:58,  2.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8037, 'grad_norm': 0.21320746839046478, 'learning_rate': 7.562956945572706e-05, 'epoch': 3.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 27%|â–ˆâ–ˆâ–‹       | 4924/18465 [12:48:52<8:19:55,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.613669514656067, 'eval_runtime': 1013.8823, 'eval_samples_per_second': 9.708, 'eval_steps_per_second': 0.608, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 5000/18465 [12:52:35<8:33:06,  2.29s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8274, 'grad_norm': 0.2463410645723343, 'learning_rate': 7.292174383969674e-05, 'epoch': 4.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–‰       | 5500/18465 [13:15:36<8:23:25,  2.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8058, 'grad_norm': 0.2571028470993042, 'learning_rate': 7.02139182236664e-05, 'epoch': 4.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 6000/18465 [13:36:27<7:51:05,  2.27s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7926, 'grad_norm': 0.27406466007232666, 'learning_rate': 6.750609260763608e-05, 'epoch': 4.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6155/18465 [14:02:02<12:37:09,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5924218893051147, 'eval_runtime': 1062.7325, 'eval_samples_per_second': 9.262, 'eval_steps_per_second': 0.58, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6500/18465 [14:15:33<6:21:10,  1.91s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7749, 'grad_norm': 0.2934473156929016, 'learning_rate': 6.479826699160574e-05, 'epoch': 5.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 7000/18465 [14:33:20<6:54:02,  2.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7764, 'grad_norm': 0.2927219867706299, 'learning_rate': 6.209044137557541e-05, 'epoch': 5.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7386/18465 [15:03:19<9:05:08,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5752484798431396, 'eval_runtime': 924.3071, 'eval_samples_per_second': 10.649, 'eval_steps_per_second': 0.666, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7500/18465 [15:07:33<6:22:12,  2.09s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7748, 'grad_norm': 0.2277224361896515, 'learning_rate': 5.938261575954509e-05, 'epoch': 6.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 8000/18465 [15:28:42<6:00:43,  2.07s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7679, 'grad_norm': 0.19758470356464386, 'learning_rate': 5.667479014351476e-05, 'epoch': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 8500/18465 [15:44:02<4:42:56,  1.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7611, 'grad_norm': 0.2536078691482544, 'learning_rate': 5.396696452748443e-05, 'epoch': 6.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8617/18465 [16:02:15<9:34:43,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5626046657562256, 'eval_runtime': 852.0821, 'eval_samples_per_second': 11.552, 'eval_steps_per_second': 0.723, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 9000/18465 [16:15:50<5:20:44,  2.03s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7487, 'grad_norm': 0.229537233710289, 'learning_rate': 5.125913891145411e-05, 'epoch': 7.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 9500/18465 [16:34:39<5:47:51,  2.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7307, 'grad_norm': 0.23780874907970428, 'learning_rate': 4.855131329542378e-05, 'epoch': 7.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9848/18465 [17:09:12<7:12:31,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5475730895996094, 'eval_runtime': 1279.0529, 'eval_samples_per_second': 7.696, 'eval_steps_per_second': 0.482, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 10000/18465 [17:17:21<5:30:58,  2.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7584, 'grad_norm': 0.23942220211029053, 'learning_rate': 4.584348767939345e-05, 'epoch': 8.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 10500/18465 [17:36:15<4:18:14,  1.95s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7313, 'grad_norm': 0.2655499279499054, 'learning_rate': 4.3135662063363117e-05, 'epoch': 8.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 11000/18465 [17:54:07<4:31:35,  2.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7435, 'grad_norm': 0.24380697309970856, 'learning_rate': 4.0427836447332795e-05, 'epoch': 8.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11079/18465 [18:11:22<5:57:06,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5386842489242554, 'eval_runtime': 864.887, 'eval_samples_per_second': 11.381, 'eval_steps_per_second': 0.712, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11500/18465 [18:26:32<3:53:21,  2.01s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7352, 'grad_norm': 0.2692797780036926, 'learning_rate': 3.772001083130247e-05, 'epoch': 9.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 12000/18465 [18:45:19<4:00:44,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7327, 'grad_norm': 0.23657335340976715, 'learning_rate': 3.501218521527214e-05, 'epoch': 9.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12310/18465 [19:09:33<5:33:12,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.529298186302185, 'eval_runtime': 791.4374, 'eval_samples_per_second': 12.437, 'eval_steps_per_second': 0.778, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 12500/18465 [19:16:21<3:29:04,  2.10s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.717, 'grad_norm': 0.2811238765716553, 'learning_rate': 3.230435959924181e-05, 'epoch': 10.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 13000/18465 [19:36:41<3:42:45,  2.45s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7167, 'grad_norm': 0.2645471692085266, 'learning_rate': 2.9596533983211482e-05, 'epoch': 10.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 13500/18465 [19:54:32<2:51:02,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7228, 'grad_norm': 0.31828320026397705, 'learning_rate': 2.6888708367181153e-05, 'epoch': 10.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 13541/18465 [20:09:31<4:16:57,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5237170457839966, 'eval_runtime': 810.1524, 'eval_samples_per_second': 12.15, 'eval_steps_per_second': 0.76, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 14000/18465 [20:26:50<2:46:35,  2.24s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7121, 'grad_norm': 0.24876298010349274, 'learning_rate': 2.418088275115083e-05, 'epoch': 11.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14500/18465 [20:45:17<2:23:21,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7076, 'grad_norm': 0.3201294243335724, 'learning_rate': 2.14730571351205e-05, 'epoch': 11.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 14772/18465 [21:09:17<3:19:33,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5178865194320679, 'eval_runtime': 835.7198, 'eval_samples_per_second': 11.778, 'eval_steps_per_second': 0.737, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 15000/18465 [21:18:00<2:12:57,  2.30s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7034, 'grad_norm': 0.28505027294158936, 'learning_rate': 1.8765231519090172e-05, 'epoch': 12.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15500/18465 [21:36:25<2:15:03,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.722, 'grad_norm': 0.2720876932144165, 'learning_rate': 1.6057405903059843e-05, 'epoch': 12.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 16000/18465 [21:55:07<1:38:38,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.711, 'grad_norm': 0.30954286456108093, 'learning_rate': 1.3349580287029517e-05, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 16003/18465 [22:10:05<2:30:42,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5148471593856812, 'eval_runtime': 884.8254, 'eval_samples_per_second': 11.124, 'eval_steps_per_second': 0.696, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16500/18465 [22:30:34<1:17:53,  2.38s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7081, 'grad_norm': 0.2785217761993408, 'learning_rate': 1.0641754670999188e-05, 'epoch': 13.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17000/18465 [22:51:40<57:47,  2.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6975, 'grad_norm': 0.326979398727417, 'learning_rate': 7.933929054968862e-06, 'epoch': 13.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 17234/18465 [23:24:58<1:40:36,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.511889934539795, 'eval_runtime': 1197.5932, 'eval_samples_per_second': 8.219, 'eval_steps_per_second': 0.514, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17500/18465 [23:36:24<37:41,  2.34s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7044, 'grad_norm': 0.33532893657684326, 'learning_rate': 5.226103438938533e-06, 'epoch': 14.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 18000/18465 [23:56:41<30:42,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7034, 'grad_norm': 0.2590237259864807, 'learning_rate': 2.5182778229082047e-06, 'epoch': 14.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18465/18465 [24:31:43<00:00,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5114909410476685, 'eval_runtime': 925.7911, 'eval_samples_per_second': 10.632, 'eval_steps_per_second': 0.665, 'epoch': 15.0}\n",
      "{'train_runtime': 88303.587, 'train_samples_per_second': 1.672, 'train_steps_per_second': 0.209, 'train_loss': 1.78713118106151, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18465, training_loss=1.78713118106151, metrics={'train_runtime': 88303.587, 'train_samples_per_second': 1.672, 'train_steps_per_second': 0.209, 'total_flos': 2.59039270075392e+16, 'train_loss': 1.78713118106151, 'epoch': 15.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = trainer.evaluate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 70.4313, 'eval_samples_per_second': 139.753, 'eval_steps_per_second': 8.746, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question, model, tokenizer, max_length=512):\n",
    "    input_text = \"Assuming you are working as Doctor. Please answer this question: \" + question\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"], \n",
    "        max_length=256, \n",
    "        num_beams=5, \n",
    "        early_stopping=True\n",
    "    )\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the treatments for spinocerebellar ataxia type 36\n",
      "Answer: These resources address the diagnosis or management of spinocerebellar ataxia type 36: - Gene Review: Gene Review: Spinocerebellar Ataxia Type 36 - Genetic Testing Registry: Spinocerebellar ataxia type 36 These resources from MedlinePlus offer information about the diagnosis and management of various health conditions: - Diagnostic Tests - Drug Therapy - Surgery and Rehabilitation - Genetic Counseling - Palliative Care\n"
     ]
    }
   ],
   "source": [
    "# Example question 1\n",
    "question = \"What are the treatments for spinocerebellar ataxia type 36\"\n",
    "\n",
    "# Generate the answer\n",
    "answer = generate_answer(question, model, tokenizer)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is Fuchs endothelial dystrophy inherited ?\n",
      "Answer: This condition is inherited in an autosomal recessive pattern, which means both copies of the gene in each cell have mutations. The parents of an individual with an autosomal recessive condition each carry one copy of the mutated gene, but they typically do not show signs and symptoms of the condition.\n"
     ]
    }
   ],
   "source": [
    "# Example question 1\n",
    "question = \"Is Fuchs endothelial dystrophy inherited ?\"\n",
    "\n",
    "# Generate the answer\n",
    "answer = generate_answer(question, model, tokenizer)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Is Fuchs endothelial dystrophy inherited ?',\n",
       " 'answer': 'In some cases, Fuchs endothelial dystrophy appears to be inherited in an autosomal dominant pattern, which means one copy of the altered gene in each cell is sufficient to cause the disorder. When this condition is caused by a mutation in the COL8A2 gene, it is inherited in an autosomal dominant pattern. In addition, an autosomal dominant inheritance pattern is apparent in some situations in which the condition is caused by alterations in an unknown gene.  In many families, the inheritance pattern is unknown.  Some cases result from new mutations in a gene and occur in people with no history of the disorder in their family.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./biomrcmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./biotokenizer/tokenizer_config.json',\n",
       " './biotokenizer/special_tokens_map.json',\n",
       " './biotokenizer/spiece.model',\n",
       " './biotokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('./biotokenizer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
